predictions.csv (for procedural is done on last 5 testcases from traindataset which were removed from training (we only trained on first 1000))

# ğŸ§  Math Solver â€” AI-Powered Reasoning Engine  
> A hybrid Chain-of-Thought and Program-Aided solver for mathematical reasoning, built to push the limits of LLM-based problem solving.

---

## ğŸš€ Overview

**Math Solver** is an intelligent reasoning engine that combines **Chain-of-Thought prompting**, **Program-Aided Language (PAL)** execution, and **self-consistency verification** to solve complex math problems.  
It is designed to **mimic human problem-solving reasoning** â€” breaking down problems step by step and verifying answers programmatically.  

The system supports:
- Arithmetic reasoning  
- Word problems  
- Algebraic and logical tasks  
- Custom prompt templates for fine-grained control  

This project was developed for an AI hackathon to showcase how structured prompting and reasoning verification can drastically improve LLM accuracy in math tasks.

---

## ğŸ§© Features

âœ… **Multi-Strategy Solvers**  
- *Chain-of-Thought (CoT)* reasoning  
- *Program-Aided Language (PAL)* solving via Python execution  
- *Self-Consistency voting* across multiple reasoning paths  

âœ… **Configurable Architecture**  
- Modular design via `config.yaml`  
- Plug-and-play solvers: CoT, PAL, or hybrid  

âœ… **Data-Driven Evaluation**  
- Evaluate models on datasets like `math_train_9k.csv` or `testmath.csv`  
- Auto-logs predictions and reasoning traces  

âœ… **Prompt Engineering Suite**  
- Templates for arithmetic, reasoning, and PAL prompts  
- Few-shot retriever for efficient contextualization  

âœ… **Explainable Outputs**  
- Generates structured reasoning traces (`traces.jsonl`)  
- Produces verified answers in `outputs/math_predictions.csv`

---

## ğŸ—ï¸ Project Structure

```
math-solver-full/
â”œâ”€â”€ config.yaml                # Configuration for model + solver setup
â”œâ”€â”€ main.py                    # Main entry point
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ PLACEHOLDER_KEYS.txt       # Add your API keys here
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ math_train_9k.csv
â”‚   â””â”€â”€ testmath.csv
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ math_predictions.csv
â”‚   â””â”€â”€ traces.jsonl
â”‚
â”œâ”€â”€ prompts/
â”‚   â”œâ”€â”€ cot_arithmetic_template.txt
â”‚   â”œâ”€â”€ cot_reasoning_template.txt
â”‚   â””â”€â”€ pal_template.txt
â”‚
â””â”€â”€ src/
    â”œâ”€â”€ cot_solver.py
    â”œâ”€â”€ pal_solver.py
    â”œâ”€â”€ self_consistency.py
    â”œâ”€â”€ verifier.py
    â”œâ”€â”€ normalizer.py
    â”œâ”€â”€ writer.py
    â”œâ”€â”€ loader.py
    â””â”€â”€ few_shot_retriever.py
```

---

## âš™ï¸ Installation

### 1ï¸âƒ£ Clone the repo
```bash
git clone https://github.com/yourusername/math-solver.git
cd math-solver
```

### 2ï¸âƒ£ Install dependencies
```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Add your API keys  
Create a `.env` or update `PLACEHOLDER_KEYS.txt` with your OpenAI or LLM provider keys:
```
OPENAI_API_KEY=your_key_here
```

---

## ğŸ§ª Usage

### Run the solver
```bash
python main.py --config config.yaml
```

### Choose a solving strategy  
Edit `config.yaml` to switch between:
```yaml
solver_type: "cot"     # Chain of Thought
# solver_type: "pal"   # Program-Aided Language
# solver_type: "hybrid" # CoT + PAL with self-consistency
```

### Evaluate on dataset
```bash
python main.py --eval --data data/testmath.csv
```

### Output
- `outputs/math_predictions.csv` â†’ final answers  
- `outputs/traces.jsonl` â†’ reasoning traces for analysis  

---

## ğŸ” Example

**Input**
```
If 3x + 2 = 11, what is x?
```

**Chain-of-Thought Trace**
```
3x + 2 = 11 â†’ 3x = 9 â†’ x = 3
```

**Output**
```
Answer: 3
```

---

## ğŸ§  Architecture

```text
Question â†’ Retriever â†’ Prompt Builder â†’ Solver (CoT/PAL) â†’ Verifier â†’ Writer
```

- **Retriever**: Selects few-shot examples  
- **Solver**: Executes reasoning (text-based or Python-based)  
- **Verifier**: Checks and normalizes results  
- **Writer**: Stores outputs for evaluation  

---

## ğŸ“Š Evaluation Metrics

| Metric | Description |
|--------|--------------|
| Accuracy | Correct predictions vs ground truth |
| Consistency | Agreement across reasoning samples |
| Trace Quality | Depth and clarity of reasoning steps |

---

## ğŸŒŸ Future Enhancements

- ğŸ”§ Web UI for real-time problem solving  
- ğŸ§© Integration with symbolic math (SymPy)  
- ğŸ¤– Reinforcement learning from reasoning feedback  
- ğŸ“š Multi-domain reasoning (physics, logic, etc.)

---

## ğŸ§‘â€ğŸ’» Contributors

- **Team Name** â€“ Interstellar 
- **Team Member(s)** â€“ Amey Taksali, Pakhi Debnath, Ridhima Gupta 

---

## ğŸ License

This project is released under the **MIT License**.  
Feel free to fork, improve, and experiment responsibly.


# ğŸ§  Multi-Hop Reasoning Engine  
> *An intelligent retrieval-augmented reasoning framework for multi-step logical inference powered by LLMs.*

---

## ğŸš€ Overview

**Multi-Hop Reasoning Engine** is an advanced AI system designed to perform *multi-step reasoning* across textual information.  
Instead of answering questions in isolation, it chains evidence from multiple passages or data points â€” similar to how humans connect facts to derive conclusions.

The project demonstrates a **hybrid architecture combining retrieval, semantic embeddings, and language model reasoning**, making it ideal for:
- Multi-hop question answering (QA)
- Knowledge graph reasoning  
- Contextual information synthesis  
- Explainable AI pipelines  

This system was built for an **AI Hackathon** to explore how LLMs can reason over structured and unstructured data in a transparent and traceable manner.

---

## ğŸ§© Features

âœ… **Multi-Hop Reasoning**  
Performs multi-step logical inference over multiple sources of information.  

âœ… **Retrieval-Augmented Generation (RAG)**  
Integrates semantic retrieval and context injection before reasoning.  

âœ… **Dynamic Prompt Construction**  
Prompts are programmatically built using templates and retrieved context.  

âœ… **Explainable Traces**  
Outputs include reasoning paths for interpretability and debugging.  

âœ… **Plug-and-Play Model Interface**  
Supports various LLM APIs via modular client wrappers.  

âœ… **Caching and Indexing**  
Optimized for repeated queries using cached embeddings and semantic indices.

---

## ğŸ—ï¸ Project Structure

```
multi-hop-reasoning/
â”œâ”€â”€ config.py                # Global configurations
â”œâ”€â”€ main.py                  # Entry point for running reasoning pipeline
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ .env.example             # Example environment file for API keys
â”œâ”€â”€ train.csv                # Training data (if applicable)
â”œâ”€â”€ test.csv                 # Test data
â”‚
â”œâ”€â”€ preprocessing/
â”‚   â””â”€â”€ build_index.py       # Builds embedding-based index for retrieval
â”‚
â”œâ”€â”€ indexing/
â”‚   â””â”€â”€ semantic_index.py    # Handles semantic search and retrieval
â”‚
â”œâ”€â”€ inference/
â”‚   â”œâ”€â”€ reasoning_engine.py  # Core reasoning pipeline
â”‚   â”œâ”€â”€ llm_client.py        # LLM API integration
â”‚   â””â”€â”€ response_parser.py   # Cleans and parses model responses
â”‚
â”œâ”€â”€ prompts/
â”‚   â””â”€â”€ prompt_builder.py    # Builds structured prompts dynamically
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ data_loader.py       # Loads datasets and text corpora
â”‚   â”œâ”€â”€ embedding_generator.py # Creates embeddings for retrieval
â”‚   â””â”€â”€ pattern_extractor.py # Extracts logical patterns from text
â”‚
â”œâ”€â”€ indices/                 # Storage for built indices
â”‚   â””â”€â”€ .gitkeep
â”‚
â””â”€â”€ cache/                   # Cache for embeddings and responses
    â””â”€â”€ .gitkeep
```

---

## âš™ï¸ Installation

### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/yourusername/multi-hop-reasoning.git
cd multi-hop-reasoning
```

### 2ï¸âƒ£ Set up environment
```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Configure API keys  
Create a `.env` file based on `.env.example`:
```
OPENAI_API_KEY=your_api_key_here
```

---

## ğŸ§ª Usage

### Run the reasoning pipeline
```bash
python main.py --config config.py
```

### Example: Multi-hop question
**Input:**
> "Who is the author of the book written by the person who invented the light bulb?"

**Pipeline Steps:**
1. Retrieve related facts about the light bulb.  
2. Find who invented it (Thomas Edison).  
3. Search for books authored by Edison.  
4. Combine the information and reason through context.  

**Output:**
```
Answer: Thomas Edison is the author of "The Wizard of Menlo Park".
Reasoning Path: [light bulb â†’ Thomas Edison â†’ authored book]
```

---

## ğŸ” Core Architecture

```text
Question â†’ Preprocessor â†’ Retriever â†’ Prompt Builder â†’ LLM Reasoning Engine â†’ Parser â†’ Final Answer
```

- **Preprocessor:** Tokenizes and indexes text corpora  
- **Retriever:** Retrieves top-k relevant chunks using semantic similarity  
- **Prompt Builder:** Dynamically constructs reasoning prompts  
- **Reasoning Engine:** Performs iterative multi-hop reasoning  
- **Parser:** Extracts structured answers and reasoning chains  

---

## âš¡ Example Workflow

```bash
# Build embedding index
python preprocessing/build_index.py

# Run inference
python inference/reasoning_engine.py --question "What was discovered by the student of Socrates?"
```

**Output Example:**
```
Answer: Plato discovered the Theory of Forms.
Evidence Chain: [Socrates â†’ Plato â†’ Theory of Forms]
```

---

## ğŸ§  How It Works

### 1. Semantic Retrieval  
Uses **vector embeddings** to find relevant text chunks for a given query.

### 2. Dynamic Prompt Construction  
Builds structured multi-hop prompts with evidence chaining.

### 3. Iterative Reasoning  
Executes multi-turn reasoning using the LLM, guided by retrieved context.

### 4. Parsing and Verification  
Parses reasoning traces, verifies consistency, and formats the final output.

---

## ğŸ“Š Evaluation

| Metric | Description |
|---------|--------------|
| Reasoning Accuracy | Correctness of multi-hop chains |
| Evidence Coverage | Number of relevant facts retrieved |
| Coherence | Logical flow of reasoning steps |
| Interpretability | Clarity of generated reasoning traces |

---

## ğŸŒŸ Future Enhancements

- ğŸ§© Integration with **Graph Databases (Neo4j)** for structured reasoning  
- ğŸ§® Support for **Knowledge Graph Augmentation**  
- ğŸ§  **Reinforcement Learning from Reasoning Feedback (RLRF)**  
- ğŸŒ Web dashboard for visualizing reasoning paths  

---

## ğŸ§‘â€ğŸ’» Contributors

- **Team Name** â€“ Team Interstellar
- **Team Member(s)** â€“ Amey Taksali, Pakhi Debnath, Ridhima Gupta 

---

## ğŸ License

This project is released under the **MIT License**.  
You are free to use, modify, and share it with attribution.
